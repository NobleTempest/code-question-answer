{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install transformers datasets"
      ],
      "metadata": {
        "id": "DXw-cVBkBHmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LKiQLXGj6SHk"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import RobertaTokenizer, RobertaModel, RobertaConfig\n",
        "import datasets\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "gmJhs4K8BGQ4"
      },
      "outputs": [],
      "source": [
        "max_source_length = 256\n",
        "max_target_length = 30\n",
        "truncate_variable_train = 5600\n",
        "truncate_variable_dev = 700"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4ft96sE6SHm"
      },
      "outputs": [],
      "source": [
        "dataset ={'train':[], 'test':[], 'dev':[]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpWGdY026SHm"
      },
      "outputs": [],
      "source": [
        "def convert_to_dataset(filename, stage, examples):\n",
        "  idx = 0\n",
        "  codefile = os.path.join(filename, stage + \".code\")\n",
        "  quesfile = os.path.join(filename, stage + \".question\")\n",
        "  ansfile = os.path.join(filename, stage + \".answer\")\n",
        "  with open(codefile,encoding=\"utf-8\") as code_f:\n",
        "      with open(ansfile, encoding=\"utf-8\") as ans_f:\n",
        "          with open(quesfile, encoding=\"utf-8\") as ques_f:\n",
        "              for codeline, quesline, ansline in zip(code_f,ques_f,ans_f):\n",
        "                  code = codeline.strip()\n",
        "                  question = quesline.strip()\n",
        "                  ans = ansline.strip()\n",
        "                  temp_list = {'code':code,'questions':question,'answer':ans}\n",
        "                  examples[stage].append(temp_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeVw8s9D6SHn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "514dca4e-ef57-4fd4-e11a-6431005557ab"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-290184b0735e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconvert_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconvert_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dev'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconvert_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-db57be728864>\u001b[0m in \u001b[0;36mconvert_to_dataset\u001b[0;34m(filename, stage, examples)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mquesfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".question\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mansfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".answer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodefile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcode_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mansfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mans_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquesfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mques_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/train/train.code'"
          ]
        }
      ],
      "source": [
        "convert_to_dataset('/train', 'train', dataset)\n",
        "convert_to_dataset('/valid', 'dev', dataset)\n",
        "convert_to_dataset('/test', 'test', dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmRSy2X-6SHn"
      },
      "outputs": [],
      "source": [
        "json_object = json.dumps(dataset)\n",
        "with open(\"codeQA.json\", \"w\") as outfile:\n",
        "    outfile.write(json_object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KFz6_xma6WxV"
      },
      "outputs": [],
      "source": [
        "dataset = datasets.DatasetDict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iAUaiY-BGQ7"
      },
      "outputs": [],
      "source": [
        "from datasets import DatasetDict, load_dataset\n",
        "dataset = load_dataset('json', data_files='/codeQA.json', field='train')\n",
        "dataset2 = load_dataset('json' ,data_files='/codeQA.json', field='test')\n",
        "dataset3 = load_dataset('json',data_files='/codeQA.json', field='dev')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['test'] = dataset2['train']\n",
        "dataset['dev'] = dataset3['train']"
      ],
      "metadata": {
        "id": "aegjVg3-GNiI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "v3JFPnyzBGQ7"
      },
      "outputs": [],
      "source": [
        "def convert_examples_to_features(dataset, tokenizer, stage=None):\n",
        "    features = []\n",
        "    for example_index, example in enumerate(dataset[stage]):\n",
        "        #source\n",
        "        source_question_tokens = tokenizer.tokenize(example['questions'])\n",
        "        source_code_tokens = tokenizer.tokenize(example['code'])\n",
        "        source_tokens = source_question_tokens + [tokenizer.sep_token] + source_code_tokens\n",
        "        source_tokens = source_tokens[:max_source_length-2]\n",
        "        source_tokens =[tokenizer.cls_token]+source_tokens+[tokenizer.sep_token]\n",
        "        source_ids =  tokenizer.convert_tokens_to_ids(source_tokens) \n",
        "        source_mask = [1] * (len(source_tokens))\n",
        "        padding_length = max_source_length - len(source_ids)\n",
        "        source_ids+=[tokenizer.pad_token_id]*padding_length\n",
        "        source_mask+=[0]*padding_length\n",
        " \n",
        "        #target\n",
        "        if stage==\"test\":\n",
        "            target_tokens = tokenizer.tokenize(\"None\")\n",
        "        else:\n",
        "            target_tokens = tokenizer.tokenize(example['answer'])[:max_target_length-2]\n",
        "        target_tokens = [tokenizer.cls_token]+target_tokens+[tokenizer.sep_token]            \n",
        "        target_ids = tokenizer.convert_tokens_to_ids(target_tokens)\n",
        "        target_mask = [1] *len(target_ids)\n",
        "        padding_length = max_target_length - len(target_ids)\n",
        "        target_ids+=[tokenizer.pad_token_id]*padding_length\n",
        "        target_mask+=[0]*padding_length   \n",
        "\n",
        "        features.append({'source_ids':source_ids ,'source_mask':source_mask ,'target_ids':target_ids ,'target_mask':target_mask})\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AY_bcT9HBGQ8"
      },
      "outputs": [],
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7yi3k9eRBGQ8"
      },
      "outputs": [],
      "source": [
        "dataset_token ={'train':[],'test':[],'dev':[]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ztMnznNuBGQ9"
      },
      "outputs": [],
      "source": [
        "feature1 = convert_examples_to_features(dataset, tokenizer, stage='train')\n",
        "feature2 = convert_examples_to_features(dataset, tokenizer, stage='test')\n",
        "feature3 = convert_examples_to_features(dataset, tokenizer, stage='dev')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_token['train'] = feature1\n",
        "dataset_token['test'] = feature2\n",
        "dataset_token['dev'] = feature3"
      ],
      "metadata": {
        "id": "BYunWuHpIO_l"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_token['train'] = dataset_token['train'][:truncate_variable_train]\n",
        "dataset_token['test'] = dataset_token['test'][:truncate_variable_dev]\n",
        "dataset_token['dev'] = dataset_token['dev'][:truncate_variable_dev]"
      ],
      "metadata": {
        "id": "VRIiHJ4CSFV8"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset_token['test'][600]['source_mask'])"
      ],
      "metadata": {
        "id": "5eJbfXUxXwAc",
        "outputId": "3ab3f808-8e30-439a-9ede-27505327cdc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_object = json.dumps(dataset_token, indent=1)\n",
        "with open(\"token.json\", \"w\") as outfile:\n",
        "    outfile.write(json_object)"
      ],
      "metadata": {
        "id": "ZN539njkI7J3"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j3Z7Ks6HVXmR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "xcode.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "cbc5014ed32a3511c99c810aecedbd8e5a5c878610fa20b4667810c497ccaeea"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}