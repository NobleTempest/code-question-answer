{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finetuning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNfsV+snXFlpVTnufR2E4hW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "f4_cU_tqMIDq"
      },
      "outputs": [],
      "source": [
        "pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import RobertaTokenizer, RobertaModel, RobertaConfig, TrainingArguments, Trainer, AutoTokenizer, AutoModelForMaskedLM\n",
        "import datasets\n",
        "import itertools"
      ],
      "metadata": {
        "id": "9iiuxGfXMOIR"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import DatasetDict, load_dataset\n",
        "dataset = load_dataset('json', data_files='/token.json', field='train')\n",
        "dataset2 = load_dataset('json' ,data_files='/token.json', field='test')\n",
        "dataset3 = load_dataset('json',data_files='/token.json', field='dev')"
      ],
      "metadata": {
        "id": "T4wXTG7KMTjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['test'] = dataset2['train']\n",
        "dataset['dev'] = dataset3['train']"
      ],
      "metadata": {
        "id": "x5mmBaROOeOP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "HW6Mn312Ohz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a85ac895-7f30-49bf-db5b-420e1063b193"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask'],\n",
              "        num_rows: 11200\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/codebert-base-mlm')\n",
        "model = AutoModelForMaskedLM.from_pretrained('microsoft/codebert-base-mlm')"
      ],
      "metadata": {
        "id": "f9yhl32UUP3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = transformers.DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")"
      ],
      "metadata": {
        "id": "sm5JbKnnX029"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='test-trainer',\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    save_steps=10000,\n",
        "    prediction_loss_only=True\n",
        ")"
      ],
      "metadata": {
        "id": "GBwEYqAwX7Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset['train'],\n",
        "    eval_dataset=dataset['dev']\n",
        ")"
      ],
      "metadata": {
        "id": "rGWJM4OdPI13"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "o4Bywj0rPqhG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "bdc24a34-2f8a-43d1-fdcd-29761722cdc2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 11200\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2800\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2800' max='2800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2800/2800 13:55, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.201100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.892200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.751000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.690700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.638900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2800, training_loss=1.8131037248883928, metrics={'train_runtime': 835.5768, 'train_samples_per_second': 13.404, 'train_steps_per_second': 3.351, 'total_flos': 1474286594457600.0, 'train_loss': 1.8131037248883928, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('/modelv1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yVuH3vrdXDO",
        "outputId": "14a0d879-d3f0-4248-e5f5-32dabaad71ac"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /modelv1\n",
            "Configuration saved in /modelv1/config.json\n",
            "Model weights saved in /modelv1/pytorch_model.bin\n"
          ]
        }
      ]
    }
  ]
}